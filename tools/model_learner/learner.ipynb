{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METAINFO_COLUMNS_COUNT = 0\n",
    "INPUT_LAYER_SIZE = 64 * 12\n",
    "WEIGHT_SCALE = 128.0\n",
    "PRECISE_WEIGHT_SCALE = 64.0\n",
    "\n",
    "BATCH_SIZE = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPYDatasetConverter:\n",
    "    def __init__(self, file_path, chunk_size_mb=10):\n",
    "        self.file_path = file_path\n",
    "        self.record_size = 100\n",
    "        self.chunk_size = chunk_size_mb * 1024 * 1024\n",
    "        \n",
    "        self.chunk_size = (self.chunk_size // self.record_size) * self.record_size\n",
    "        \n",
    "        file_size = os.path.getsize(file_path)\n",
    "        self.num_samples = file_size // self.record_size\n",
    "        \n",
    "    def convert_to_npy(self, output_prefix):\n",
    "        all_indices = []\n",
    "        all_offsets = []\n",
    "        all_targets = []\n",
    "        \n",
    "        current_offset = 0\n",
    "        \n",
    "        with open(self.file_path, 'rb') as f:\n",
    "            while True:\n",
    "                chunk_bytes = f.read(self.chunk_size)\n",
    "                if len(chunk_bytes) == 0:\n",
    "                    break\n",
    "                    \n",
    "                indices, offsets, targets = self._process_chunk(chunk_bytes, current_offset)\n",
    "                \n",
    "                if len(targets) > 0:\n",
    "                    all_indices.append(indices)\n",
    "                    all_offsets.append(offsets)\n",
    "                    all_targets.append(targets)\n",
    "                    \n",
    "                    current_offset += len(indices)\n",
    "        \n",
    "        if all_indices:\n",
    "            all_indices = np.concatenate(all_indices)\n",
    "            all_offsets = np.concatenate(all_offsets)\n",
    "            all_targets = np.concatenate(all_targets)\n",
    "            \n",
    "            np.save(f\"{output_prefix}_indices.npy\", all_indices)\n",
    "            np.save(f\"{output_prefix}_offsets.npy\", all_offsets)\n",
    "            np.save(f\"{output_prefix}_targets.npy\", all_targets)\n",
    "            \n",
    "            print(f\"Conversion complete. Samples: {len(all_targets)}\")\n",
    "        else:\n",
    "            print(\"No data found in file\")\n",
    "        \n",
    "    def _process_chunk(self, chunk_bytes, global_offset):\n",
    "        chunk_size = len(chunk_bytes)\n",
    "        full_records_size = (chunk_size // self.record_size) * self.record_size\n",
    "        \n",
    "        if full_records_size == 0:\n",
    "            return np.array([], dtype=np.int64), np.array([], dtype=np.int64), np.array([], dtype=np.float32)\n",
    "        \n",
    "        chunk_bytes = chunk_bytes[:full_records_size]\n",
    "        num_records = full_records_size // self.record_size\n",
    "        \n",
    "        chunk_array = np.frombuffer(chunk_bytes, dtype=np.uint8)\n",
    "        batch_bytes = chunk_array.reshape(num_records, self.record_size)\n",
    "        \n",
    "        targets = np.frombuffer(batch_bytes[:, 96:].tobytes(), dtype='<f4').copy()\n",
    "        \n",
    "        features_packed = batch_bytes[:, :96]\n",
    "        features = np.unpackbits(features_packed, axis=1)\n",
    "        nonzero_mask = features == 1\n",
    "        \n",
    "        _, feature_indices = np.where(nonzero_mask)\n",
    "        indices = feature_indices.astype(np.int64)\n",
    "        \n",
    "        counts = np.sum(nonzero_mask, axis=1)\n",
    "        offsets_array = np.concatenate([[0], np.cumsum(counts)[:-1]]).copy()\n",
    "        offsets = offsets_array.astype(np.int64) + global_offset\n",
    "        \n",
    "        return indices, offsets, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPYDataset(Dataset):\n",
    "    def __init__(self, prefix):\n",
    "        indices = np.load(f\"{prefix}_indices.npy\")\n",
    "        offsets = np.load(f\"{prefix}_offsets.npy\")\n",
    "        targets = np.load(f\"{prefix}_targets.npy\")\n",
    "\n",
    "        self.indices = torch.from_numpy(indices).long()\n",
    "        self.targets = torch.from_numpy(targets).float()\n",
    "\n",
    "        offsets = torch.from_numpy(offsets).long()\n",
    "        total_indices = torch.tensor([self.indices.shape[0]], dtype=torch.long, device=self.indices.device)\n",
    "        self.offsets = torch.cat((offsets, total_indices))\n",
    "        self.sample_offsets = self.offsets[:-1]\n",
    "        self.lengths = self.offsets[1:] - self.sample_offsets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return int(idx)\n",
    "\n",
    "    def collate_fn(self, batch_indices):\n",
    "        batch_indices = torch.as_tensor(batch_indices, dtype=torch.long, device=self.indices.device)\n",
    "\n",
    "        lengths = self.lengths.index_select(0, batch_indices)\n",
    "        sample_starts = self.sample_offsets.index_select(0, batch_indices)\n",
    "        prefix = torch.cumsum(lengths, dim=0) - lengths\n",
    "        total_elems = int(lengths.sum().item())\n",
    "\n",
    "        base = sample_starts - prefix\n",
    "        expanded_base = base.repeat_interleave(lengths)\n",
    "        positions = torch.arange(total_elems, device=self.indices.device, dtype=torch.long)\n",
    "        positions = positions + expanded_base\n",
    "        indices = self.indices.index_select(0, positions)\n",
    "\n",
    "        offsets = prefix\n",
    "        targets = self.targets.index_select(0, batch_indices)\n",
    "\n",
    "        return (indices, offsets), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.compressed_data = f.read()\n",
    "        self.record_size = 100\n",
    "        self.num_samples = len(self.compressed_data) // self.record_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.record_size\n",
    "        end = start + self.record_size\n",
    "        record_bytes = self.compressed_data[start:end]\n",
    "        return record_bytes\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        batch_bytes = np.frombuffer(b''.join(batch), dtype=np.uint8)\n",
    "        batch_size = len(batch)\n",
    "        batch_bytes = batch_bytes.reshape(batch_size, -1)\n",
    "        \n",
    "        targets = np.frombuffer(batch_bytes[:, 96:].tobytes(), dtype='<f4').copy()\n",
    "        \n",
    "        features_packed = batch_bytes[:, :96]\n",
    "        \n",
    "        features = np.unpackbits(features_packed, axis=1)\n",
    "        \n",
    "        nonzero_mask = features == 1\n",
    "        _, feature_indices = np.where(nonzero_mask)\n",
    "        \n",
    "        indices = torch.from_numpy(feature_indices.copy()).long()\n",
    "        \n",
    "        counts = np.sum(nonzero_mask, axis=1)\n",
    "        \n",
    "        offsets_array = np.concatenate([[0], np.cumsum(counts)[:-1]]).copy()\n",
    "        offsets = torch.from_numpy(offsets_array).long()\n",
    "        \n",
    "        targets_tensor = torch.from_numpy(targets).float()\n",
    "        return (indices, offsets), targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this when RAM is more important than CPU\n",
    "\n",
    "dataset = CompressedDataset('/home/wind-eagle/Chess/dataset/2_0/train.qds')\n",
    "testset = CompressedDataset('/home/wind-eagle/Chess/dataset/2_0/test.qds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this when CPU is more important than RAM\n",
    "\n",
    "# converter = NPYDatasetConverter(\"/home/wind-eagle/Chess/dataset/train.qds\")\n",
    "# converter.convert_to_npy(\"train\")\n",
    "# converter = NPYDatasetConverter(\"/home/wind-eagle/Chess/dataset/test.qds\")\n",
    "# converter.convert_to_npy(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = NPYDataset(\"train\")\n",
    "# testset = NPYDataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=6,\n",
    "        prefetch_factor=4,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=dataset.collate_fn\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=6,\n",
    "        prefetch_factor=4,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=testset.collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClippedReLU(nn.Module):\n",
    "    def __init__(self, clip_value: float):\n",
    "        super(ClippedReLU, self).__init__()\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(x.relu(), max=self.clip_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNNE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNNE, self).__init__()\n",
    "\n",
    "        self.embedding_bag = nn.EmbeddingBag(\n",
    "            num_embeddings=768,\n",
    "            embedding_dim=256,\n",
    "            mode='sum',\n",
    "            sparse=False,\n",
    "            device=cuda\n",
    "        )\n",
    "        \n",
    "        self.embedding_bias = nn.Parameter(torch.zeros(256))\n",
    "        \n",
    "        self.feature = nn.Sequential()\n",
    "        self.main = nn.Sequential()\n",
    "\n",
    "        self.feature.add_module('clipped_relu1', ClippedReLU(1.0))\n",
    "\n",
    "        self.main.add_module('first', nn.Linear(512, 16))\n",
    "        self.main.add_module('clipped_relu2', ClippedReLU(1.0))\n",
    "\n",
    "        self.main.add_module('second', nn.Linear(16, 32))\n",
    "        self.main.add_module('clipped_relu3', ClippedReLU(1.0))\n",
    "\n",
    "        self.main.add_module('third', nn.Linear(32, 1))\n",
    "        self.main.add_module('sigmoid', nn.Sigmoid())\n",
    "\n",
    "        self.register_buffer('xor_indices', self._create_xor_indices())\n",
    "        self.register_buffer('branch2_mapping', self._create_branch2_mapping())\n",
    "\n",
    "    def _create_xor_indices(self):\n",
    "        xor_indices = torch.zeros(768, dtype=torch.long)\n",
    "        for i in range(768):\n",
    "            xor_indices[i] = (i % 64) ^ 56 + (i // 64) * 64\n",
    "        return xor_indices\n",
    "\n",
    "    def _create_branch2_mapping(self):\n",
    "        mapping = torch.zeros(768, dtype=torch.long)\n",
    "        rearranged = torch.cat([torch.arange(384, 768), torch.arange(0, 384)])\n",
    "        for i in range(768):\n",
    "            mapping[i] = rearranged[self.xor_indices[i]]\n",
    "        return mapping\n",
    "\n",
    "    def forward(self, x):\n",
    "        indices, offsets = x\n",
    "\n",
    "        embedded1 = self.embedding_bag(indices, offsets) + self.embedding_bias.to(device=cuda)\n",
    "        branch1 = self.feature(embedded1)\n",
    "        \n",
    "        branch2_indices = self.branch2_mapping.to(device=cuda)[indices]\n",
    "        embedded2 = self.embedding_bag(branch2_indices, offsets) + self.embedding_bias.to(device=cuda)\n",
    "        branch2 = self.feature(embedded2)\n",
    "        \n",
    "        combined = torch.cat((branch1, branch2), dim=1)\n",
    "        return self.main(combined)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, X, y):\n",
    "    y = (y + 1.0) / 2\n",
    "    y_pred = model(X)\n",
    "    assert y_pred.dim() == 1\n",
    "    loss = torch.sum((y - y_pred) ** 2) / y_pred.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({ 'figure.facecolor': 'black', 'axes.facecolor': 'black', 'text.color': 'white', 'axes.labelcolor': 'white', 'xtick.color': 'white', 'ytick.color': 'white' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, scheduler, lr_limit):    \n",
    "    fig = plt.figure()\n",
    "    axes = fig.add_subplot()\n",
    "    hfig = display(fig, display_id=True)\n",
    "    train_plot_data_x, train_plot_data_y, test_plot_data_y = [], [], []\n",
    "    axes.plot(train_plot_data_x, train_plot_data_y)\n",
    "    fig.canvas.draw()\n",
    "    hfig.update(fig)\n",
    "\n",
    "    epoch_num = 0\n",
    "    with tqdm() as progress:\n",
    "        while True:\n",
    "            if opt.param_groups[0][\"lr\"] + 1e-9 < lr_limit:\n",
    "                break\n",
    "            history = []\n",
    "            test_history = []\n",
    "            for features, targets in loader:\n",
    "                indices, offsets = features\n",
    "                indices = indices.to(cuda, non_blocking=True)\n",
    "                offsets = offsets.to(cuda, non_blocking=True)\n",
    "                targets = targets.to(cuda, non_blocking=True)\n",
    "                \n",
    "                loss = get_loss(model, (indices, offsets), targets)\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.main.first.weight.data = torch.clamp(model.main.first.weight.data, min=-128.0 / WEIGHT_SCALE, max=127.0 / WEIGHT_SCALE)\n",
    "                    model.main.second.weight.data = torch.clamp(model.main.second.weight.data, min=-32768.0 / WEIGHT_SCALE / PRECISE_WEIGHT_SCALE, max=32767.0 / WEIGHT_SCALE / PRECISE_WEIGHT_SCALE)\n",
    "\n",
    "                history.append(loss.data.cpu().numpy())\n",
    "\n",
    "            for features, targets in test_loader:\n",
    "                indices, offsets = features\n",
    "                indices = indices.to(cuda, non_blocking=True)\n",
    "                offsets = offsets.to(cuda, non_blocking=True)\n",
    "                targets = targets.to(cuda, non_blocking=True)\n",
    "                \n",
    "                loss = get_loss(model, (indices, offsets), targets)\n",
    "                test_history.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            train_loss = sum(history) / len(history)\n",
    "            test_loss = sum(test_history) / len(test_history)\n",
    "\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "            train_plot_data_x.append(epoch_num)\n",
    "            train_plot_data_y.append(train_loss)\n",
    "            test_plot_data_y.append(test_loss)\n",
    "\n",
    "            axes.cla()\n",
    "            axes.plot(train_plot_data_x[-50:], train_plot_data_y[-50:])\n",
    "            axes.plot(train_plot_data_x[-50:], test_plot_data_y[-50:])\n",
    "            fig.canvas.draw()\n",
    "            hfig.update(fig)\n",
    "\n",
    "            epoch_num += 1\n",
    "            progress.update(1)\n",
    "            progress.set_description(f'Average batch loss = {train_loss:.6f}, average test loss = {test_loss:.6f}, lr = {opt.param_groups[0][\"lr\"]:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(f, arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            print(\"{0:0.5f}\".format(arr[i][j]), ' ', file=f, sep=\"\", end=\"\")\n",
    "\n",
    "def print_biases(f, arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "            print(\"{0:0.5f}\".format(arr[i]), ' ', file=f, sep=\"\", end=\"\")\n",
    "\n",
    "def print_model(model, name):\n",
    "    with open(name, 'w') as f:\n",
    "        feature_transformer_weights = model.embedding_bag.weight.detach().cpu().numpy()\n",
    "        feature_transformer_biases = model.embedding_bias.detach().cpu().numpy()\n",
    "        \n",
    "        print_weights(f, feature_transformer_weights)\n",
    "        print_biases(f, feature_transformer_biases)\n",
    "        \n",
    "        print_weights(f, model.main.first.weight.T.detach().cpu().numpy())\n",
    "        print_biases(f, model.main.first.bias.detach().cpu().numpy())\n",
    "        print_weights(f, model.main.second.weight.T.detach().cpu().numpy())\n",
    "        print_biases(f, model.main.second.bias.detach().cpu().numpy())\n",
    "        print_weights(f, model.main.third.weight.T.detach().cpu().numpy())\n",
    "        print_biases(f, model.main.third.bias.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "model = QNNE().to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/wind-eagle/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/wind-eagle/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\nTypeError: CompressedDataset.collate_fn() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m opt = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.01\u001b[39m * np.cbrt(\u001b[32m0.1\u001b[39m), weight_decay=\u001b[32m7e-6\u001b[39m)\n\u001b[32m      2\u001b[39m scheduler = ReduceLROnPlateau(opt, patience=\u001b[32m16\u001b[39m, factor=np.cbrt(\u001b[32m0.1\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcbrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcbrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m scheduler = ReduceLROnPlateau(opt, patience=\u001b[32m4\u001b[39m, factor=np.cbrt(\u001b[32m0.1\u001b[39m))\n\u001b[32m      5\u001b[39m train_model(model, opt, scheduler, \u001b[32m0.0001\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, opt, scheduler, lr_limit)\u001b[39m\n\u001b[32m     15\u001b[39m history = []\n\u001b[32m     16\u001b[39m test_history = []\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1515\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1513\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1514\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1515\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1550\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mTypeError\u001b[39m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/wind-eagle/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/wind-eagle/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\nTypeError: CompressedDataset.collate_fn() takes 1 positional argument but 2 were given\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.01 * np.cbrt(0.1), weight_decay=7e-6)\n",
    "scheduler = ReduceLROnPlateau(opt, patience=16, factor=np.cbrt(0.1))\n",
    "train_model(model, opt, scheduler, 0.001 * np.cbrt(0.1) * np.cbrt(0.1))\n",
    "scheduler = ReduceLROnPlateau(opt, patience=4, factor=np.cbrt(0.1))\n",
    "train_model(model, opt, scheduler, 0.0001)\n",
    "scheduler = ReduceLROnPlateau(opt, patience=2, factor=np.cbrt(0.1))\n",
    "train_model(model, opt, scheduler, 0.00001)\n",
    "scheduler = ReduceLROnPlateau(opt, patience=1, factor=np.cbrt(0.1))\n",
    "train_model(model, opt, scheduler, 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(model, 'model.qnne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
