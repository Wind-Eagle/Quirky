{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'target'\n",
    "METAINFO_COLUMNS = ['stage', 'move_count', 'game_index', 'weight']\n",
    "METAINFO_COLUMNS_COUNT = len(METAINFO_COLUMNS)\n",
    "STAGE_INDEX = 0\n",
    "MOVE_COUNT_INDEX = 1\n",
    "WEIGHT_INDEX = 3\n",
    "TARGET_INDEX = -1\n",
    "\n",
    "STARTPOS_STAGE = 24\n",
    "NUMBER_OF_FEATURES = 52\n",
    "\n",
    "TAPERED_EVAL_BOUND = 6 + NUMBER_OF_FEATURES + 64 * 6\n",
    "\n",
    "NUMBER_OF_GAMES = 100000\n",
    "BATCH_SIZE = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_number_weights = [0.00001, 0.00008, 0.00024, 0.00043, 0.00057, 0.0007, 0.00085, 0.00105, 0.00139, 0.00181, 0.00244, 0.00375, 0.00521, 0.00731, 0.00973, 0.01254, 0.01645, 0.02553, 0.03776, 0.05396, 0.07285, 0.09648, 0.12129, 0.15135, 0.18169, 0.21407, 0.245858, 0.277823, 0.309948, 0.341158, 0.37258, 0.402667, 0.432192, 0.45969, 0.487255, 0.514445, 0.539746, 0.564126, 0.587609, 0.609724, 0.629945, 0.650371, 0.668892, 0.687291, 0.704763, 0.720856, 0.735872, 0.750076, 0.763791, 0.776711, 0.78944, 0.801965, 0.814003, 0.824748, 0.83541, 0.844756, 0.853865, 0.862123, 0.870204, 0.878105, 0.885155, 0.891836, 0.898314, 0.90489, 0.91067, 0.915671, 0.920825, 0.925534, 0.930256, 0.934641, 0.93932, 0.943253, 0.947136, 0.950907, 0.954602, 0.957961, 0.961024, 0.963216, 0.965767, 0.968335, 0.970546, 0.972861, 0.974728, 0.976481, 0.978039, 0.979738, 0.981401, 0.98274, 0.984218, 0.985646, 0.986751, 0.987752, 0.988783, 0.989843, 0.990658, 0.991329, 0.99217, 0.992891, 0.993448, 0.99403]\n",
    "stage_weights = [0.864812, 0.862839, 1.5417, 2.14211, 0.637247]\n",
    "\n",
    "class Row:\n",
    "    def __init__(self, csv_line):\n",
    "        self.X = np.array(csv_line[METAINFO_COLUMNS_COUNT:TARGET_INDEX], dtype=np.single)\n",
    "        self.y = csv_line[TARGET_INDEX]\n",
    "        move_number_weight = 1\n",
    "        stage_weight = stage_weights[math.floor(csv_line[STAGE_INDEX] + 0.25) // 5]\n",
    "        if csv_line[MOVE_COUNT_INDEX] <= 100:\n",
    "            move_number_weight = move_number_weights[math.floor(csv_line[MOVE_COUNT_INDEX] + 0.25) - 1] * 100000 / NUMBER_OF_GAMES\n",
    "        # self.w = move_number_weight * stage_weight\n",
    "        self.w = 1\n",
    "        self.X = np.concatenate((self.X, self.X))\n",
    "        self.X[:TAPERED_EVAL_BOUND] *= csv_line[STAGE_INDEX] / 24\n",
    "        self.X[TAPERED_EVAL_BOUND:] *= 1 - csv_line[STAGE_INDEX] / 24\n",
    "        \n",
    "    def get_not_features_count():\n",
    "        return METAINFO_COLUMNS_COUNT + 1\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_y(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_w(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatCalcer:\n",
    "    def __init__(self, row_size):\n",
    "        self.max = np.zeros(row_size, dtype=np.single)\n",
    "        self.min = np.full(row_size, 2 ** 16, dtype=np.single)\n",
    "        self.cnt = 0\n",
    "\n",
    "    def process_row(self, row):\n",
    "        self.max = np.maximum(self.max, row.get_X())\n",
    "        self.min = np.minimum(self.min, row.get_X())\n",
    "        self.cnt += 1\n",
    "\n",
    "    def get_max(self):\n",
    "        return self.max\n",
    "    \n",
    "    def get_min(self):\n",
    "        return self.min\n",
    "    \n",
    "    def get_cnt(self):\n",
    "        return self.cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedDatasetHolder:\n",
    "    def __init__(self, dataset_dir, sample_test_rate):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.dataset_chunks = [entry for entry in os.listdir(dataset_dir) if os.path.isfile(os.path.join(self.dataset_dir, entry))]\n",
    "        self.n = len(self.dataset_chunks)\n",
    "        \n",
    "        self.train_chunks_count = math.floor(len(self.dataset_chunks) * sample_test_rate + 0.49)\n",
    "        print(self.train_chunks_count)\n",
    "        self.dataset_chunks = sorted(self.dataset_chunks)\n",
    "        print(self.dataset_chunks)\n",
    "\n",
    "        self.open_files()\n",
    "\n",
    "        self.shuffle()\n",
    "        \n",
    "        self.stat_calcer = StatCalcer(self.get_features_count())\n",
    "        self.calc_stat()\n",
    "    \n",
    "    def open_files(self):\n",
    "        self.chunk_files = [open(os.path.join(self.dataset_dir, filename)) for filename in self.dataset_chunks]\n",
    "        self.csv_readers = [csv.reader(file) for file in self.chunk_files]\n",
    "        for i in range(self.n):\n",
    "            self.header = np.array(next(self.csv_readers[i]))\n",
    "\n",
    "    def close_files(self):\n",
    "        for file in self.chunk_files:\n",
    "            file.close()\n",
    "\n",
    "    def reopen_files(self):\n",
    "        self.close_files()\n",
    "        self.open_files()\n",
    "\n",
    "    def calc_stat(self):\n",
    "        print(\"calc\")\n",
    "        self.reopen_files()\n",
    "        for i in range(self.n):\n",
    "            while True:\n",
    "                try:\n",
    "                    row = Row(np.array(next(self.csv_readers[i]), dtype=np.single))\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                except Exception:\n",
    "                    raise RuntimeError(\"Stopped!\")\n",
    "                self.stat_calcer.process_row(row)\n",
    "        self.reopen_files()\n",
    "        print(self.stat_calcer.get_cnt())\n",
    "\n",
    "    def shuffle_file(self, filename):\n",
    "        with open(os.path.join(self.dataset_dir, filename)) as file:\n",
    "            lines = np.array(file.readlines())\n",
    "            np.random.shuffle(lines[1:])\n",
    "        with open(os.path.join(self.dataset_dir, filename), 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        \n",
    "    def shuffle(self):\n",
    "        print(\"shuffle\")\n",
    "        for filename in self.dataset_chunks:\n",
    "            self.shuffle_file(filename)\n",
    "        self.reopen_files()\n",
    "\n",
    "    def get_batch(self, left_pos, right_pos, batch_size, norm):\n",
    "        batch_X = np.zeros((batch_size, self.get_features_count()), dtype=np.single)\n",
    "        batch_y = np.zeros(batch_size, dtype=np.single)\n",
    "        batch_w = np.zeros(batch_size, dtype=np.single)\n",
    "        size = 0\n",
    "        while size < batch_size:\n",
    "            pos = random.randint(left_pos, right_pos - 1)\n",
    "            try:\n",
    "                row = Row(np.array(next(self.csv_readers[pos]), dtype=np.single))\n",
    "            except StopIteration:\n",
    "                self.shuffle()\n",
    "                return self.get_batch(left_pos, right_pos, batch_size, norm)\n",
    "            except Exception:\n",
    "                raise RuntimeError(\"Stopped!\")\n",
    "            batch_X[size, :] = row.get_X() / norm\n",
    "            batch_y[size] = row.get_y()\n",
    "            batch_w[size] = row.get_w()\n",
    "            size += 1\n",
    "        return batch_X, batch_y, batch_w\n",
    "\n",
    "    def get_train_batch(self, batch_size, norm):\n",
    "        return self.get_batch(0, self.train_chunks_count, batch_size, norm)\n",
    "    \n",
    "    def get_test_batch(self, batch_size, norm):\n",
    "        return self.get_batch(self.train_chunks_count, self.n, batch_size, norm)\n",
    "    \n",
    "    def get_features_count(self):\n",
    "        return 64 * 12 + 6 * 2 + NUMBER_OF_FEATURES * 2\n",
    "    \n",
    "    def get_stat_calcer(self):\n",
    "        return self.stat_calcer\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_holder = DistributedDatasetHolder('/home/wind-eagle/quirky_data/dataset', 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_calcer = dataset_holder.get_stat_calcer()\n",
    "X_max = stat_calcer.get_max()\n",
    "X_min = stat_calcer.get_min()\n",
    "X_norm = X_max - X_min\n",
    "X_norm = np.maximum(np.min(X_norm[X_norm > 1e-9]), X_norm)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('linear', nn.Linear(dataset_holder.get_features_count(), 1, bias=False))\n",
    "model.add_module('sigmoid', nn.Sigmoid())\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def get_loss(model, X, y, w, C=0.0):\n",
    "    y_pred = model(X)[:, 0]\n",
    "    assert y_pred.dim() == 1\n",
    "    loss = torch.sum(w * ((y - y_pred) ** 2)) / torch.sum(w)\n",
    "    loss += C * torch.norm(model.linear.weight, 2)\n",
    "    return loss\n",
    "\n",
    "def get_weights():\n",
    "    ww = (model.linear.weight[0]).detach().numpy() / X_norm\n",
    "    for i in range(5):\n",
    "        l = 6 + NUMBER_OF_FEATURES + 64 * i\n",
    "        r = 6 + NUMBER_OF_FEATURES + 64 * (i + 1)\n",
    "        if i == 0:\n",
    "            l += 8\n",
    "            r -= 8\n",
    "        m = np.median(ww[l:r])\n",
    "        ww[l:r] -= m\n",
    "        ww[i] += m\n",
    "\n",
    "    for i in range(5):\n",
    "        l = TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * i\n",
    "        r = TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * (i + 1)\n",
    "        if i == 0:\n",
    "            l += 8\n",
    "            r -= 8\n",
    "        m = np.median(ww[l:r])\n",
    "        ww[l:r] -= m\n",
    "        ww[i + TAPERED_EVAL_BOUND] += m\n",
    "\n",
    "    ww = (ww / ((ww[0] + ww[TAPERED_EVAL_BOUND]) / 2) * 100).astype(np.int32)\n",
    "    return ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_learning(iter_count):\n",
    "    C = 3e-5\n",
    "    history = []\n",
    "\n",
    "    for i in range(iter_count):\n",
    "        np_X, np_y, np_w = dataset_holder.get_train_batch(BATCH_SIZE, X_norm)\n",
    "        X_batch = torch.tensor(np_X, dtype=torch.float32)\n",
    "        y_batch = torch.tensor(np_y, dtype=torch.float32)\n",
    "        w_batch = torch.tensor(np_w, dtype=torch.float32)\n",
    "\n",
    "        loss = get_loss(model, X_batch, y_batch, w_batch, C=C)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            weights = get_weights()\n",
    "            print(weights[:6])\n",
    "            print(weights[TAPERED_EVAL_BOUND:TAPERED_EVAL_BOUND + 6])\n",
    "            print(weights[6 : 6 + NUMBER_OF_FEATURES])\n",
    "            print(weights[TAPERED_EVAL_BOUND + 6 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES])\n",
    "        if i % 100 == 0:\n",
    "            np_X, np_y, np_w = dataset_holder.get_test_batch(BATCH_SIZE, X_norm)\n",
    "            X_test_batch = torch.tensor(np_X, dtype=torch.float32)\n",
    "            y_test_batch = torch.tensor(np_y, dtype=torch.float32)\n",
    "            w_test_batch = torch.tensor(np_w, dtype=torch.float32)\n",
    "            test_loss = get_loss(model,\n",
    "                torch.tensor(X_test_batch, dtype=torch.float32),\n",
    "                torch.tensor(y_test_batch, dtype=torch.float32),\n",
    "                torch.tensor(w_test_batch, dtype=torch.float32),\n",
    "                C=0.0).detach().numpy().sum()\n",
    "            train_loss = np.mean(history[-40:])\n",
    "            print(f\"step #{i}, train_loss = {train_loss:.4f}, test_loss = {test_loss:.4f}\")\n",
    "        elif i % 10 == 0:\n",
    "            train_loss = np.mean(history[-40:])\n",
    "            print(f\"step #{i}, train_loss = {train_loss:.4f}\")\n",
    "        \n",
    "\n",
    "main_learning(7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[TAPERED_EVAL_BOUND:TAPERED_EVAL_BOUND + 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[6 : NUMBER_OF_FEATURES + 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[TAPERED_EVAL_BOUND + 6 : TAPERED_EVAL_BOUND + NUMBER_OF_FEATURES + 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mat(mat):\n",
    "    plt.matshow(mat)\n",
    "    for (x, y), value in np.ndenumerate(mat):\n",
    "        plt.text(y, x, f\"{value}\", va=\"center\", ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 0 : 6 + NUMBER_OF_FEATURES + 64 * 1].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 1 : 6 + NUMBER_OF_FEATURES + 64 * 2].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 2 : 6 + NUMBER_OF_FEATURES + 64 * 3].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 3 : 6 + NUMBER_OF_FEATURES + 64 * 4].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 4 : 6 + NUMBER_OF_FEATURES + 64 * 5].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + NUMBER_OF_FEATURES + 64 * 5 : 6 + NUMBER_OF_FEATURES + 64 * 6].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 0 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 1].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 1 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 2].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 2 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 3].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 3 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 4].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 4 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 5].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 5 : TAPERED_EVAL_BOUND + 6 + NUMBER_OF_FEATURES + 64 * 6].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_of_psq = weights[6 + NUMBER_OF_FEATURES:]\n",
    "psq = [(0, 0)] * (64 * 6)\n",
    "for i in range(6):\n",
    "    for j in range(64):\n",
    "        psq[i * 64 + j] = (weights_of_psq[i * 64 + j], weights_of_psq[TAPERED_EVAL_BOUND + i * 64 + j])\n",
    "\n",
    "for i in range(len(psq)):\n",
    "    print(f\"ScorePair({psq[i][0]}, {psq[i][1]}),\", end=\"\")\n",
    "    if i % 8 == 7:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_of_features = weights[6:]\n",
    "features = [(0, 0)] * (NUMBER_OF_FEATURES)\n",
    "for i in range(NUMBER_OF_FEATURES):\n",
    "    features[i] = (weights_of_features[i], weights_of_features[TAPERED_EVAL_BOUND + i])\n",
    "\n",
    "for i in range(NUMBER_OF_FEATURES):\n",
    "    print(f\"ScorePair({features[i][0]}, {features[i][1]}),\", end=\"\")\n",
    "    if i % 8 == 7:\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
