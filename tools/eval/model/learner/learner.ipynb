{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTPOS_STAGE = 24\n",
    "TARGET_COLUMN = 'target'\n",
    "METAINFO_COLUMNS = ['stage', 'move_count', 'game_index', 'weight']\n",
    "METAINFO_COLUMNS_COUNT = len(METAINFO_COLUMNS)\n",
    "STAGE_INDEX = 0\n",
    "MOVE_COUNT_INDEX = 1\n",
    "WEIGHT_INDEX = 3\n",
    "TARGET_INDEX = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row:\n",
    "    def __init__(self, csv_line):\n",
    "        self.X = np.array(csv_line[METAINFO_COLUMNS_COUNT:TARGET_INDEX], dtype=np.single)\n",
    "        self.y = csv_line[TARGET_INDEX]\n",
    "        self.w = csv_line[WEIGHT_INDEX]\n",
    "        self.X = np.concatenate((self.X, \n",
    "                                self.X[6 + 7 + 64 * 5 : 6 + 7 + 64 * 6]))\n",
    "        self.X[6 + 7 + 64 * 5 : 6 + 7 + 64 * 6] *= self.X[STAGE_INDEX] / 24\n",
    "        self.X[6 + 7 + 64 * 6 : 6 + 7 + 64 * 7] *= 1 - self.X[STAGE_INDEX] / 24\n",
    "        \n",
    "    def get_not_features_count():\n",
    "        return METAINFO_COLUMNS_COUNT + 1\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_y(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_w(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatCalcer:\n",
    "    def __init__(self, row_size):\n",
    "        self.max = np.zeros(row_size, dtype=np.single)\n",
    "        self.min = np.full(row_size, 2 ** 16, dtype=np.single)\n",
    "        self.cnt = 0\n",
    "\n",
    "    def process_row(self, row):\n",
    "        self.max = np.maximum(self.max, row.get_X())\n",
    "        self.min = np.minimum(self.min, row.get_X())\n",
    "        self.cnt += 1\n",
    "\n",
    "    def get_max(self):\n",
    "        return self.max\n",
    "    \n",
    "    def get_min(self):\n",
    "        return self.min\n",
    "    \n",
    "    def get_cnt(self):\n",
    "        return self.cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDatasetHolder:\n",
    "    def __init__(self, dataset_file, sample_test_rate):\n",
    "        with open(dataset_file) as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            self.header = np.array(next(csv_reader))\n",
    "            self.stat_calcer = StatCalcer(self.header.shape[0] - Row.get_not_features_count() + 64)\n",
    "            self.train = []\n",
    "            self.test = []\n",
    "            while True:\n",
    "                try:\n",
    "                    row = Row(np.array(next(csv_reader), dtype=np.single))\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                self.stat_calcer.process_row(row)\n",
    "                if np.random.random() < sample_test_rate:\n",
    "                    self.train.append(row)\n",
    "                else:\n",
    "                    self.test.append(row)\n",
    "            \n",
    "            self.train = np.array(self.train)\n",
    "            self.test = np.array(self.test)\n",
    "\n",
    "    def get_train_batch(self, batch_size):\n",
    "        return self.train[np.random.choice(self.train.shape[0], batch_size)]\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self.test[np.random.choice(self.test.shape[0], batch_size)]\n",
    "    \n",
    "    def get_features_count(self):\n",
    "        return self.train[0].get_X().shape[0]\n",
    "    \n",
    "    def get_stat_calcer(self):\n",
    "        return self.stat_calcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedDatasetHolder:\n",
    "    def __init__(self, dataset_dir, sample_test_rate):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.dataset_chunks = [entry for entry in os.listdir(dataset_dir) if os.path.isfile(os.path.join(self.dataset_dir, entry))]\n",
    "        self.n = len(self.dataset_chunks)\n",
    "        \n",
    "        self.train_chunks_count = math.floor(len(self.dataset_chunks) * sample_test_rate + 0.49)\n",
    "        print(self.train_chunks_count)\n",
    "        # random.shuffle(self.dataset_chunks)\n",
    "        self.dataset_chunks = sorted(self.dataset_chunks)\n",
    "        print(self.dataset_chunks)\n",
    "\n",
    "        self.open_files()\n",
    "\n",
    "        self.shuffle()\n",
    "        \n",
    "        self.stat_calcer = StatCalcer(self.header.shape[0] - Row.get_not_features_count() + 64)\n",
    "        self.calc_stat()\n",
    "    \n",
    "    def open_files(self):\n",
    "        self.chunk_files = [open(os.path.join(self.dataset_dir, filename)) for filename in self.dataset_chunks]\n",
    "        self.csv_readers = [csv.reader(file) for file in self.chunk_files]\n",
    "        for i in range(self.n):\n",
    "            self.header = np.array(next(self.csv_readers[i]))\n",
    "\n",
    "    def close_files(self):\n",
    "        for file in self.chunk_files:\n",
    "            file.close()\n",
    "\n",
    "    def reopen_files(self):\n",
    "        self.close_files()\n",
    "        self.open_files()\n",
    "\n",
    "    def calc_stat(self):\n",
    "        print(\"calc\")\n",
    "        self.reopen_files()\n",
    "        for i in range(self.n):\n",
    "            while True:\n",
    "                try:\n",
    "                    row = Row(np.array(next(self.csv_readers[i]), dtype=np.single))\n",
    "                except:\n",
    "                    break\n",
    "                self.stat_calcer.process_row(row)\n",
    "        self.reopen_files()\n",
    "        print(self.stat_calcer.get_cnt())\n",
    "\n",
    "    def shuffle_file(self, filename):\n",
    "        with open(os.path.join(self.dataset_dir, filename)) as file:\n",
    "            lines = np.array(file.readlines())\n",
    "            np.random.shuffle(lines[1:])\n",
    "        with open(os.path.join(self.dataset_dir, filename), 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        # df = pd.read_csv(os.path.join(self.dataset_dir, filename))\n",
    "        # df = df.sample(frac=1)\n",
    "        # df.to_csv(os.path.join(self.dataset_dir, filename), index=False)\n",
    "        \n",
    "    def shuffle(self):\n",
    "        print(\"shuffle\")\n",
    "        for filename in self.dataset_chunks:\n",
    "            self.shuffle_file(filename)\n",
    "        self.reopen_files()\n",
    "\n",
    "    def get_batch(self, left_pos, right_pos, batch_size):\n",
    "        batch = []\n",
    "        size = 0\n",
    "        while size < batch_size:\n",
    "            pos = random.randint(left_pos, right_pos - 1)\n",
    "            try:\n",
    "                row = Row(np.array(next(self.csv_readers[pos]), dtype=np.single))\n",
    "            except:\n",
    "                self.shuffle()\n",
    "                return self.get_batch(left_pos, right_pos, batch_size)\n",
    "            size += 1\n",
    "            batch.append(row)\n",
    "        return np.array(batch)\n",
    "\n",
    "    def get_train_batch(self, batch_size):\n",
    "        return self.get_batch(0, self.train_chunks_count, batch_size)\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self.get_batch(self.train_chunks_count, self.n, batch_size)\n",
    "    \n",
    "    def get_features_count(self):\n",
    "        return self.header.shape[0] - Row.get_not_features_count()\n",
    "    \n",
    "    def get_stat_calcer(self):\n",
    "        return self.stat_calcer\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_holder = DistributedDatasetHolder('/home/wind-eagle/quirky_data/dataset', 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_calcer = dataset_holder.get_stat_calcer()\n",
    "X_max = stat_calcer.get_max()\n",
    "X_min = stat_calcer.get_min()\n",
    "X_norm = X_max - X_min\n",
    "X_norm = np.maximum(np.min(X_norm[X_norm > 1e-9]), X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('linear', nn.Linear(dataset_holder.get_features_count() + 64, 1, bias=False))\n",
    "model.add_module('sigmoid', nn.Sigmoid())\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def get_loss(model, X, y, w, C=0.0):\n",
    "    y_pred = model(X)[:, 0]\n",
    "    assert y_pred.dim() == 1\n",
    "    loss = torch.sum(w * ((y - y_pred) ** 2)) / torch.sum(w)\n",
    "    loss += C * torch.norm(model.linear.weight, 2)\n",
    "    return loss\n",
    "\n",
    "def get_weights():\n",
    "    ww = (model.linear.weight[0]).detach().numpy() / X_norm\n",
    "    for i in range(5):\n",
    "        l = 6 + 7 + 64 * i\n",
    "        r = 6 + 7 + 64 * (i + 1)\n",
    "        if i == 0:\n",
    "            l += 8\n",
    "            r -= 8\n",
    "        m = np.median(ww[l:r])\n",
    "        ww[l:r] -= m\n",
    "        ww[i] += m\n",
    "\n",
    "    ww = (ww / ww[0] * 100).astype(np.int32)\n",
    "    return ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_learning(iter_count):\n",
    "    C = 5e-5\n",
    "    history = []\n",
    "\n",
    "    for i in range(iter_count):\n",
    "        batch = dataset_holder.get_train_batch(16384)\n",
    "        X_batch = torch.tensor([r.get_X() / X_norm for r in batch], dtype=torch.float32)\n",
    "        y_batch = torch.tensor([r.get_y() for r in batch], dtype=torch.float32)\n",
    "        w_batch = torch.tensor([r.get_w() for r in batch], dtype=torch.float32)\n",
    "\n",
    "        loss = get_loss(model, X_batch, y_batch, w_batch, C=C)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "\n",
    "        # выводим результаты\n",
    "        if i % 100 == 0:\n",
    "            print(get_weights())\n",
    "        if i % 100 == 0:\n",
    "            batch = dataset_holder.get_test_batch(16384)\n",
    "            X_test_batch = torch.tensor([r.get_X() / X_norm for r in batch], dtype=torch.float32)\n",
    "            y_test_batch = torch.tensor([r.get_y() for r in batch], dtype=torch.float32)\n",
    "            w_test_batch = torch.tensor([r.get_w() for r in batch], dtype=torch.float32)\n",
    "            test_loss = get_loss(model,\n",
    "                torch.tensor(X_test_batch, dtype=torch.float32),\n",
    "                torch.tensor(y_test_batch, dtype=torch.float32),\n",
    "                torch.tensor(w_test_batch, dtype=torch.float32),\n",
    "                C=0.0).detach().numpy().sum()\n",
    "            train_loss = np.mean(history[-40:])\n",
    "            print(f\"step #{i}, train_loss = {train_loss:.4f}, test_loss = {test_loss:.4f}\")\n",
    "        elif i % 10 == 0:\n",
    "            train_loss = np.mean(history[-40:])\n",
    "            print(f\"step #{i}, train_loss = {train_loss:.4f}\")\n",
    "        \n",
    "\n",
    "main_learning(10500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[6 : 7 + 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mat(mat, add):\n",
    "    plt.matshow(mat)\n",
    "    for (x, y), value in np.ndenumerate(mat):\n",
    "        plt.text(y, x, f\"{value}\", va=\"center\", ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 0 : 6 + 7 + 64 * 1].reshape(8, 8), weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 1 : 6 + 7 + 64 * 2].reshape(8, 8), weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 2 : 6 + 7 + 64 * 3].reshape(8, 8), weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 3 : 6 + 7 + 64 * 4].reshape(8, 8), weights[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 4 : 6 + 7 + 64 * 5].reshape(8, 8), weights[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 5 : 6 + 7 + 64 * 6].reshape(8, 8), weights[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mat(weights[6 + 7 + 64 * 6 : 6 + 7 + 64 * 7].reshape(8, 8), weights[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
